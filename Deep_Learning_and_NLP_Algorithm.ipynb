{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAPOln6BE9A6VylhsqVNHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jatingpt/Deep-Learning-and-NLP-Algorithm-Task/blob/main/Deep_Learning_and_NLP_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMbH9tWCXVYz",
        "outputId": "f330d2d3-267e-45f8-cfae-fbd6f05a9ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "zT6cY0OMZBsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var = \"Hey this is jatin and i am going to crack the interview as soon as possible.\"\n",
        "w = word_tokenize(var)\n",
        "w"
      ],
      "metadata": {
        "id": "ikwVIbnjYaBF",
        "outputId": "fbd4296c-2584-4615-f110-ff80b70e8717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey',\n",
              " 'this',\n",
              " 'is',\n",
              " 'jatin',\n",
              " 'and',\n",
              " 'i',\n",
              " 'am',\n",
              " 'going',\n",
              " 'to',\n",
              " 'crack',\n",
              " 'the',\n",
              " 'interview',\n",
              " 'as',\n",
              " 'soon',\n",
              " 'as',\n",
              " 'possible',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "var = \"Hey, what is the time today? he is a good person. He will go for spa.\"\n",
        "s = sent_tokenize(var)\n",
        "s"
      ],
      "metadata": {
        "id": "JKjmphQfZHoW",
        "outputId": "8144a10f-13d1-42ab-ec83-2af9fed52b4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey, what is the time today?', 'he is a good person.', 'He will go for spa.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in s:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "RmeWDgdRe_3L",
        "outputId": "333b26c9-b95c-4faf-c795-920d3e0534e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey, what is the time today?\n",
            "he is a good person.\n",
            "He will go for spa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "punc = list(punctuation)\n",
        "for i in punctuation:\n",
        "  if i not in punctuation:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "a4NYXIEefDUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "var = \"Hey, what is the time today? he is a good person. He will go for spa.\"\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "stop = stopwords.words(\"english\")\n",
        "stop_word_list = list(punctuation) + stop\n",
        "for i in var:\n",
        "  if i not in stop_word_list:\n",
        "    print(i)\n"
      ],
      "metadata": {
        "id": "n37Pc9KZhh84",
        "outputId": "07f48696-8975-40db-aebc-d375dade96ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            " \n",
            " \n",
            "h\n",
            "e\n",
            " \n",
            "e\n",
            " \n",
            " \n",
            "h\n",
            "e\n",
            " \n",
            " \n",
            " \n",
            "g\n",
            " \n",
            "p\n",
            "e\n",
            "r\n",
            "n\n",
            " \n",
            "H\n",
            "e\n",
            " \n",
            "w\n",
            "l\n",
            "l\n",
            " \n",
            "g\n",
            " \n",
            "f\n",
            "r\n",
            " \n",
            "p\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer, SnowballStemmer, RegexpStemmer, PorterStemmer\n",
        "l = LancasterStemmer()\n",
        "s = SnowballStemmer(\"english\")\n",
        "r = RegexpStemmer(\"ing\")\n",
        "p = PorterStemmer()"
      ],
      "metadata": {
        "id": "zL7vlWT7lV8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.stem(\"changing\")"
      ],
      "metadata": {
        "id": "UNjHXulZmXez",
        "outputId": "128944ec-8f10-4db5-8b15-9cf8bb543126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chang'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer, PorterStemmer, SnowballStemmer, RegexpStemmer\n",
        "r = RegexpStemmer(\"ing\")\n",
        "s = SnowballStemmer(\"english\")\n",
        "l = LancasterStemmer()\n",
        "p = PorterStemmer()"
      ],
      "metadata": {
        "id": "ridGgMhxm8t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"running\"\n",
        "print(l.stem(word))\n",
        "print(r.stem(word))\n",
        "print(s.stem(word))\n",
        "print(p.stem(word))\n",
        "\n",
        "word2 = \"mice\"\n",
        "print(l.stem(word2))"
      ],
      "metadata": {
        "id": "EfIHbrRLrZtW",
        "outputId": "085b0711-a938-44e9-b940-398d7aa6f687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "runn\n",
            "run\n",
            "run\n",
            "mic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "w = WordNetLemmatizer()\n",
        "word = \"mice\"\n",
        "w.lemmatize(word)"
      ],
      "metadata": {
        "id": "pCWbRFbyrgWQ",
        "outputId": "5b76f0fd-3887-45ec-e0cc-333f97409214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mouse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.lemmatize(\"mice\")"
      ],
      "metadata": {
        "id": "i1_OpPkDsXd8",
        "outputId": "d9a4f8da-f0a3-4d78-a4fa-663289cc2326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mouse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var = \"Here, are some of the rules if you are working here. Please ! maintain silence !!\"\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "stop = stopwords.words(\"english\")\n",
        "stop_word_list = stop + list(punctuation)\n",
        "for i in var.split():\n",
        "  if i not in stop_word_list:\n",
        "    print(i)\n"
      ],
      "metadata": {
        "id": "y1sdYcILs50O",
        "outputId": "ec4e6375-6c4c-4ae3-cf23-b642074902bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here,\n",
            "rules\n",
            "working\n",
            "here.\n",
            "Please\n",
            "maintain\n",
            "silence\n",
            "!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in var.split():\n",
        "    clean_word = word.strip(punctuation)  # Remove punctuation\n",
        "    if clean_word.lower() not in stop_word_list and clean_word:\n",
        "        print(clean_word)"
      ],
      "metadata": {
        "id": "fmY21n1-wse1",
        "outputId": "8acf9151-c7e8-44b5-d10b-a9a866819c05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rules\n",
            "working\n",
            "Please\n",
            "maintain\n",
            "silence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "stop = stopwords.words(\"english\")\n",
        "stop_word_list = stop + list(punctuation)\n",
        "\n",
        "var = \"Here, are some of the rules if you are working here. Please! maintain silence!!\"\n",
        "\n",
        "for word in var.split():\n",
        "    clean_word = word.strip(punctuation)  # Remove punctuation\n",
        "    if clean_word.lower() not in stop_word_list and clean_word:\n",
        "        print(clean_word)"
      ],
      "metadata": {
        "id": "cMTVojXUw38S",
        "outputId": "b691e4f7-a3f8-4ac8-ab8d-403f0d19e7ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rules\n",
            "working\n",
            "Please\n",
            "maintain\n",
            "silence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(punctuation)"
      ],
      "metadata": {
        "id": "QdsmsUzJthNY",
        "outputId": "a5242d05-5ec0-4c45-f8dd-fa9bbae00935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"#Here are a lot of examples! that a hard working person will surely succeed.\"\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "stop = stopwords.words(\"english\")\n",
        "stop_word_list = stop + list(punctuation)\n",
        "for i in sent.split():\n",
        "  cleaned_word = i.strip(punctuation)\n",
        "  if cleaned_word.lower() not in stop_word_list and cleaned_word:\n",
        "    print(i)\n"
      ],
      "metadata": {
        "id": "s406IXmKuKVg",
        "outputId": "58ceb68e-279b-4e5d-e3a7-d8c06b56b5f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lot\n",
            "examples!\n",
            "hard\n",
            "working\n",
            "person\n",
            "surely\n",
            "succeed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer, PorterStemmer, SnowballStemmer, RegexpStemmer\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "l = LancasterStemmer()\n",
        "s = SnowballStemmer(\"english\")\n",
        "p = PorterStemmer()\n",
        "r = RegexpStemmer(\"ing\")\n",
        "\n",
        "l.stem(\"running\")\n",
        "\n",
        "p.stem(\"running\")"
      ],
      "metadata": {
        "id": "K5_179Y0vNiU",
        "outputId": "f3e03a3b-da1b-468c-b3fe-63f4292ce284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'run'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "senten = \"Hey! i am ready to do the tasks... that is # @ given by the professor.\"\n",
        "stop = stopwords.words(\"english\")\n",
        "stop_word_lis = stop + list(punctuation)\n",
        "\n",
        "for i in senten.split():\n",
        "  if i not in stop_word_lis:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "Gr_LETP4yvUy",
        "outputId": "eccdc691-5747-46ee-e34e-e36af6c0ee01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey!\n",
            "ready\n",
            "tasks...\n",
            "given\n",
            "professor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "wordd = \"You are a special person for me ! # $ and we need to improve__ ourselves/\"\n",
        "stop = stopwords.words(\"english\")\n",
        "stop_word_lis = stop + list(punctuation)\n",
        "\n",
        "for i in wordd.split():\n",
        "  if i not in stop_word_lis:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "12Tv3f4d2aVl",
        "outputId": "bdfa73d6-98b3-4919-e7f2-78eb7415f7d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You\n",
            "special\n",
            "person\n",
            "need\n",
            "improve__\n",
            "ourselves/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "wordd = \"You are a special person for me ! # $ and we need to improve__ ourselves/\"\n",
        "\n",
        "stop = stopwords.words(\"english\")\n",
        "new_sent = stop + list(punctuation)\n",
        "\n",
        "for i in wordd.split():\n",
        "  if i not in new_sent:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "Ftkc88gez3YF",
        "outputId": "8ae44dde-d0cd-4f1f-b313-0d39e1204a0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "putting\n",
            "234\n",
            "!!\n",
            "@@\n",
            "numbers\n",
            "..\n",
            "randomly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lAfJPraJ1YZr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(punctuation)"
      ],
      "metadata": {
        "id": "N78mjO2D5yKf",
        "outputId": "7a16ff67-942e-4c24-b9e3-9cc580de85ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPEN AI WORK\n",
        "import openai\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "LQmEcnIY56GC",
        "outputId": "05792996-1081-4873-85f4-201d20757447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow\n"
      ],
      "metadata": {
        "id": "zEEnOv1B6VKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}